{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X-3YUo3LlSg",
        "outputId": "609f44a9-b76d-4a96-aab0-9b6845fe84b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxkY1q8JDvIw",
        "outputId": "aefb5857-e5d9-47da-9dc1-886ea4731181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================\n",
            "Model: FairBoostNet\n",
            "Confusion Matrix:\n",
            "TP: 526 \t FP: 298\n",
            "FN: 402 \t TN: 7012\n",
            "Accuracy: 0.9150279193979121\n",
            "Precision: 0.6383495145631068\n",
            "Recall: 0.5668103448275862\n",
            "F1: 0.6004566210045663\n",
            "Fairness DI: 1.3539555259086526\n",
            "Fairness EOD: 0.015257583075054648\n",
            "Fairness SPD: 0.031012291120689317\n",
            "Fairness AOD: 0.01700462879186705\n",
            "================================================================\n",
            "Model: XGBoost\n",
            "Confusion Matrix:\n",
            "TP: 561 \t FP: 345\n",
            "FN: 367 \t TN: 6965\n",
            "Accuracy: 0.9135712551590192\n",
            "Precision: 0.6192052980132451\n",
            "Recall: 0.6045258620689655\n",
            "F1: 0.6117775354416577\n",
            "Fairness DI: 1.3725946242738973\n",
            "Fairness EOD: 0.024818189064617302\n",
            "Fairness SPD: 0.03566112045357213\n",
            "Fairness AOD: 0.02336176324339507\n",
            "================================================================\n",
            "Model: Gradient Boosting\n",
            "Confusion Matrix:\n",
            "TP: 761 \t FP: 726\n",
            "FN: 167 \t TN: 6584\n",
            "Accuracy: 0.8915999028890508\n",
            "Precision: 0.511768661735037\n",
            "Recall: 0.8200431034482759\n",
            "F1: 0.6302277432712217\n",
            "Fairness DI: 1.2668570370281145\n",
            "Fairness EOD: 0.04526166239198015\n",
            "Fairness SPD: 0.04352221202846221\n",
            "Fairness AOD: 0.03445747876551497\n",
            "================================================================\n",
            "Model: AdaBoost\n",
            "Confusion Matrix:\n",
            "TP: 707 \t FP: 696\n",
            "FN: 221 \t TN: 6614\n",
            "Accuracy: 0.8886865744112649\n",
            "Precision: 0.5039201710620099\n",
            "Recall: 0.7618534482758621\n",
            "F1: 0.6066066066066067\n",
            "Fairness DI: 1.3054716828478965\n",
            "Fairness EOD: 0.05562406515653795\n",
            "Fairness SPD: 0.04635851115660106\n",
            "Fairness AOD: 0.041302897729129415\n",
            "================================================================\n",
            "Model: CatBoost\n",
            "Confusion Matrix:\n",
            "TP: 558 \t FP: 309\n",
            "FN: 370 \t TN: 7001\n",
            "Accuracy: 0.9175770818159747\n",
            "Precision: 0.643598615916955\n",
            "Recall: 0.6012931034482759\n",
            "F1: 0.6217270194986072\n",
            "Fairness DI: 1.4023342688106797\n",
            "Fairness EOD: 0.043765912852661626\n",
            "Fairness SPD: 0.03647222833411261\n",
            "Fairness AOD: 0.032024176951351666\n",
            "================================================================\n"
          ]
        }
      ],
      "source": [
        "# Core libraries for data handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Machine learning models and utilities\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "\n",
        "# For handling imbalanced datasets\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "\n",
        "# Data preprocessing and pipeline utilities\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "\n",
        "\n",
        "class DataPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, scaler_type='standard'):\n",
        "        self.num_transformer = None\n",
        "        self.cat_transformer = None\n",
        "        self.preprocessor = None\n",
        "        self.scaler = {\n",
        "            'standard': StandardScaler(),\n",
        "            'minmax': MinMaxScaler(),\n",
        "            'robust': RobustScaler()\n",
        "        }.get(scaler_type, StandardScaler())\n",
        "\n",
        "    def fit(self, X):\n",
        "        num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "        cat_cols = X.select_dtypes(include=['object']).columns\n",
        "        self.num_transformer = Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', self.scaler)\n",
        "        ])\n",
        "        self.cat_transformer = Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "        ])\n",
        "        self.preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', self.num_transformer, num_cols),\n",
        "                ('cat', self.cat_transformer, cat_cols)\n",
        "            ])\n",
        "        self.preprocessor.fit(X)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return self.preprocessor.transform(X)\n",
        "\n",
        "    def fit_transform(self, X):\n",
        "        self.fit(X)\n",
        "        return self.transform(X)\n",
        "\n",
        "\n",
        "class DataBalancer:\n",
        "    def __init__(self, method='SMOTE', random_state=None):\n",
        "        if method not in ['SMOTE', 'ROS', 'RUS']:\n",
        "            raise ValueError(\"Method must be 'SMOTE', 'ROS', or 'RUS'\")\n",
        "        self.method = method\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def balance_data(self, X, y):\n",
        "        balancer = {\n",
        "            'SMOTE': SMOTE(random_state=self.random_state),\n",
        "            'ROS': RandomOverSampler(random_state=self.random_state),\n",
        "            'RUS': RandomUnderSampler(random_state=self.random_state)\n",
        "        }.get(self.method, SMOTE(random_state=self.random_state))\n",
        "        X_balanced, y_balanced = balancer.fit_resample(X, y)\n",
        "        return X_balanced, y_balanced\n",
        "\n",
        "\n",
        "class FairnessEvaluator:\n",
        "    def __init__(self, y_true, y_pred, sensitive_features):\n",
        "        self.y_true = np.array(y_true)\n",
        "        self.y_pred = np.array(y_pred)\n",
        "        self.sensitive_features = np.array(sensitive_features).flatten()\n",
        "        self.majority_group, self.minority_group = self.identify_groups()\n",
        "\n",
        "    def identify_groups(self):\n",
        "        unique_groups, counts = np.unique(self.sensitive_features, return_counts=True)\n",
        "        majority_group = unique_groups[np.argmax(counts)]\n",
        "        minority_group = unique_groups[np.argmin(counts)]\n",
        "        return majority_group, minority_group\n",
        "\n",
        "    def disparate_impact(self):\n",
        "        majority_positive_rate = np.mean(self.y_pred[self.sensitive_features == self.majority_group])\n",
        "        minority_positive_rate = np.mean(self.y_pred[self.sensitive_features == self.minority_group])\n",
        "        return minority_positive_rate / majority_positive_rate\n",
        "\n",
        "    def statistical_parity_difference(self):\n",
        "        majority_positive_rate = np.mean(self.y_pred[self.sensitive_features == self.majority_group])\n",
        "        minority_positive_rate = np.mean(self.y_pred[self.sensitive_features == self.minority_group])\n",
        "        return minority_positive_rate - majority_positive_rate\n",
        "\n",
        "    def equal_opportunity_difference(self):\n",
        "        majority_true_positive_rate = np.mean(self.y_pred[(self.sensitive_features == self.majority_group) & (self.y_true == 1)])\n",
        "        minority_true_positive_rate = np.mean(self.y_pred[(self.sensitive_features == self.minority_group) & (self.y_true == 1)])\n",
        "        return minority_true_positive_rate - majority_true_positive_rate\n",
        "\n",
        "    def average_odds_difference(self):\n",
        "        majority_fpr = np.mean(self.y_pred[(self.sensitive_features == self.majority_group) & (self.y_true == 0)])\n",
        "        minority_fpr = np.mean(self.y_pred[(self.sensitive_features == self.minority_group) & (self.y_true == 0)])\n",
        "        fpr_diff = minority_fpr - majority_fpr\n",
        "        majority_tpr = np.mean(self.y_pred[(self.sensitive_features == self.majority_group) & (self.y_true == 1)])\n",
        "        minority_tpr = np.mean(self.y_pred[(self.sensitive_features == self.minority_group) & (self.y_true == 1)])\n",
        "        tpr_diff = minority_tpr - majority_tpr\n",
        "        return (fpr_diff + tpr_diff) / 2\n",
        "\n",
        "    def evaluate_fairness(self, metric):\n",
        "        metrics = {\n",
        "            'DI': self.disparate_impact,\n",
        "            'SPD': self.statistical_parity_difference,\n",
        "            'EOD': self.equal_opportunity_difference,\n",
        "            'AOD': self.average_odds_difference\n",
        "        }\n",
        "        return metrics[metric]()\n",
        "\n",
        "\n",
        "class FairBoostNet:\n",
        "    def __init__(self, train_age, fairness_metric):\n",
        "        self.thereshhold = 0.5\n",
        "        self.sens_train = train_age\n",
        "        self.layer_one_models = [XGBClassifier(random_state=random_state, verbosity=0),\n",
        "                                 GradientBoostingClassifier(random_state=random_state),\n",
        "                                 AdaBoostClassifier(random_state=random_state),\n",
        "                                 CatBoostClassifier(random_state=random_state, silent=True)]\n",
        "        self.meta_model = XGBClassifier(random_state=random_state, verbosity=0)\n",
        "        self.fairness_metric = fairness_metric\n",
        "        self.attention_scores = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        layer_one_fairness, layer_one_predictions = [], []\n",
        "        for model in self.layer_one_models:\n",
        "            model.fit(X, y)\n",
        "            predictions = model.predict(X)\n",
        "            layer_one_predictions.append(predictions)\n",
        "            fairness_eval_train = FairnessEvaluator(y, predictions, self.sens_train)\n",
        "            layer_one_fairness.append(fairness_eval_train.evaluate_fairness(self.fairness_metric))\n",
        "        layer_one_predictions = np.array(layer_one_predictions).T\n",
        "        fairness_scores = 1 - np.abs(np.array(layer_one_fairness))\n",
        "        self.attention_scores = fairness_scores / np.sum(fairness_scores)\n",
        "        weighted_predictions = layer_one_predictions * self.attention_scores\n",
        "        self.meta_model.fit(weighted_predictions, y)\n",
        "        return\n",
        "\n",
        "    def predict(self, X):\n",
        "        layer_one_predictions = []\n",
        "        for model in self.layer_one_models:\n",
        "            predictions = model.predict(X)\n",
        "            layer_one_predictions.append(predictions)\n",
        "        layer_one_predictions = np.array(layer_one_predictions).T\n",
        "        if self.attention_scores is None:\n",
        "            raise ValueError(\"Attention scores have not been set. Please train the model first.\")\n",
        "        weighted_predictions = layer_one_predictions * self.attention_scores\n",
        "        final_predictions = self.meta_model.predict(weighted_predictions)\n",
        "        return final_predictions\n",
        "\n",
        "def evaluate_model(model, X_train, y_train, X_test, y_test, X_train_age, X_test_age, fairness_metric):\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    test_metrics = {\n",
        "        'Confusion Matrix': confusion_matrix(y_test, predictions),\n",
        "        'Accuracy': accuracy_score(y_test, predictions),\n",
        "        'Precision': precision_score(y_test, predictions, zero_division=0),\n",
        "        'Recall': recall_score(y_test, predictions),\n",
        "        'F1': f1_score(y_test, predictions)\n",
        "    }\n",
        "    fairness_eval_test = FairnessEvaluator(y_test, predictions, X_test_age)\n",
        "    test_metrics['Fairness DI'] = fairness_eval_test.disparate_impact()\n",
        "    test_metrics['Fairness EOD'] = fairness_eval_test.evaluate_fairness(fairness_metric)\n",
        "    test_metrics['Fairness SPD'] = fairness_eval_test.statistical_parity_difference()\n",
        "    test_metrics['Fairness AOD'] = fairness_eval_test.average_odds_difference()\n",
        "    return test_metrics\n",
        "\n",
        "def fairboostnet(X_train, y_train, X_test, y_test, X_train_age, X_test_age, fairness_metric):\n",
        "    fairboost_model = FairBoostNet(X_train_age, fairness_metric)\n",
        "    fairboost_model.fit(X_train, y_train)\n",
        "    predictions = fairboost_model.predict(X_test)\n",
        "    fairness_eval_test = FairnessEvaluator(y_test, predictions, X_test_age)\n",
        "    test_metrics = evaluate_model(fairboost_model, X_train, y_train, X_test, y_test, X_train_age, X_test_age, fairness_metric)\n",
        "    test_metrics['Fairness DI'] = fairness_eval_test.disparate_impact()\n",
        "    test_metrics['Fairness EOD'] = fairness_eval_test.evaluate_fairness(fairness_metric)\n",
        "    test_metrics['Fairness SPD'] = fairness_eval_test.statistical_parity_difference()\n",
        "    test_metrics['Fairness AOD'] = fairness_eval_test.average_odds_difference()\n",
        "    return test_metrics\n",
        "\n",
        "\n",
        "# Setting Random State\n",
        "random_state = 2024\n",
        "np.random.seed(random_state)\n",
        "# Load dataset\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CSI 5137/Project/bank-additional-full.csv', delimiter=';')\n",
        "dataset['age'] = (dataset['age'] > 35).astype(int)\n",
        "# Separating features and target variable\n",
        "data = dataset.drop('y', axis=1)\n",
        "labels = dataset['y'].map({'yes': 1, 'no': 0})\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=random_state)\n",
        "# Extract gender information for fairness evaluation\n",
        "age_train, age_test = X_train['age'], X_test['age']\n",
        "# Drop 'CODE_GENDER' column if not needed for further processing\n",
        "X_train = X_train.drop(['age'], axis=1)\n",
        "X_test = X_test.drop(['age'], axis=1)\n",
        "# Preprocess the dataset\n",
        "preprocessor = DataPreprocessor(scaler_type='minmax')\n",
        "preprocessed_X_train = preprocessor.fit_transform(X_train)\n",
        "preprocessed_X_test = preprocessor.transform(X_test)\n",
        "updated_preprocessed_X_train = np.concatenate([age_train.to_numpy().reshape(-1, 1), preprocessed_X_train], axis=1)\n",
        "updated_preprocessed_X_test = np.concatenate([age_test.to_numpy().reshape(-1, 1), preprocessed_X_test], axis=1)\n",
        "# Instantiate Data Balancer and balance the training data\n",
        "data_balancer = DataBalancer(method='SMOTE', random_state=random_state)\n",
        "balanced_X_train, balanced_y_train = data_balancer.balance_data(updated_preprocessed_X_train, y_train)\n",
        "# Extract sensitive attribute\n",
        "X_train_age = balanced_X_train[:, [0]]\n",
        "X_test_age = updated_preprocessed_X_test[:, [0]]\n",
        "fairness_metric = 'EOD'\n",
        "models = {\n",
        "    'FairBoostNet': fairboostnet,\n",
        "    'XGBoost': XGBClassifier(random_state=random_state, verbosity=0),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=random_state),\n",
        "    'AdaBoost': AdaBoostClassifier(random_state=random_state),\n",
        "    'CatBoost': CatBoostClassifier(random_state=random_state, silent=True)\n",
        "}\n",
        "print(\"================================================================\")\n",
        "for name, model_function in models.items():\n",
        "    if name == 'FairBoostNet':\n",
        "        test_metrics = model_function(balanced_X_train, balanced_y_train, updated_preprocessed_X_test, y_test, X_train_age, X_test_age, fairness_metric)\n",
        "    else:\n",
        "        model_function.fit(balanced_X_train, balanced_y_train)\n",
        "        test_metrics = evaluate_model(model_function, balanced_X_train, balanced_y_train, updated_preprocessed_X_test, y_test, X_train_age, X_test_age, fairness_metric)\n",
        "    print(f\"Model: {name}\")\n",
        "    for metric_name, metric_value in test_metrics.items():\n",
        "        if metric_name == 'Confusion Matrix':\n",
        "            print(f\"{metric_name}:\")\n",
        "            print(f\"TP: {metric_value[1, 1]} \\t FP: {metric_value[0, 1]}\")\n",
        "            print(f\"FN: {metric_value[1, 0]} \\t TN: {metric_value[0, 0]}\")\n",
        "        else:\n",
        "            print(f\"{metric_name}: {metric_value}\")\n",
        "    print(\"================================================================\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}